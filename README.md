# Introduction

---

>**Note**: `README.md` contains the full report of this work.
I work faster using present project structure, therefore Jupyter Notebooks are not included.
Additionally, running multiple experiments is a lot more convenient this way. 
Exploratory data analysis is also omitted, since MNIST is well studied dataset and intended to be a "plug-and-play" solution.

>**Note**: I do not support this report with rigorous mathematical derivations, but rather attempting to show my understanding of the model and applied techniques. 

>**Note**: this is my very first project on GANs. Some parts may be rough around the edges.

>**Note**: I just found out that it is impossible to add several model graphs to the tensorboard. 
To capture the most information I add the complete graph of the **Encoder V1** as it includes the Generator and the example Encoder. 

This is the test task for the Deep Learning R&D Intern position at NVIDIA.
Task consists of two major parts:
1. Training DCGAN on MNIST dataset
2. Effective navigation in the latent variable space with a NN and iterative optimizer

All results and visualisations are stored as an interactive Tensorboard log.


# Getting started

---

>**Note**: to be able to run modules of this project one would need to install the required libraries. 
While most of the libraries used in this project are quite common, there are a few tools that are not so popular.
The general recommendation in such cases is to use virtual environment ([one of many guides](https://realpython.com/python-virtual-environments-a-primer/)).

>**Note**: this project is developed and tested on MacOS Big Sur and Python 3.9. The appropriate behavior on other systems is expected but not guaranteed.

To run this project, please install the dependencies using the following command:
```shell
pip install torch torchvision tensorboard scipy pyswarms hydra omegaconf tqdm
```

Alternatively, `requirements.txt` is also attached to prevent the undefined behavior with different versions of installed libraries.
To install packages from the `requirements.txt` run the following command in your terminal emulator:
```shell
pip install -r requirements.txt
```

Be aware that installing from the `requirements.txt` leads to the installation of redundant libraries, such as Jupyter Lab and others.

In order to run visualisations in an interactive environment, please navigate to the project root and run the following in you terminal emulator:
```shell
tensorboard --logdir results/
```

Tensorboard visualisations contain the graphs for all the runs and output visualisation.

# Task 1: DCGAN

---

This part addresses the DCGAN training issue. 

### 1.1 Background
GANs are a special branch of the deep learning models.
The main idea of this approach is to train two networks, each representing an "agent", in a competitive (adversarial) environment.
One network, called the Generator, is trained to map an arbitrary n-dimensional vector sampled from the latent variable space to the target distribution.
Another network, the Discriminator, is trained to identify whether the given input is real or generated by the Generator.

The goal of training can be seen as the game of Rock-Paper-Scissors with two players. 
Let's define a reward on 1 for winning a particular round, a reward of -1 for loosing a round, and a zero reward for draw.
Assume that one player uniformly samples an action from random. 
In this case the second player cannot derive a superior winning strategy against the first player.
Prioritizing one of the actions (making the probability of any action more than one third) inevitably leads to loosing more often compared to the uniform sampling of actions.
In case of two players, the observation is symmetric, so the second player can't improve the strategy either.
This case is called an equilibrium. 
Such state essentially is the goal of training a GAN: to reach the state when none of the players can further improve the strategy.

### 1.2 Model architecture

Several DCGAN architectures were tested for this problem, including variant with linear layers.
Final solution `dcgan_v3.py` is composed of the pretty shallow networks without any linear layers as proposed in the [original DCGAN paper](https://arxiv.org/abs/1511.06434). 
Small depth of the networks is motivated by the simplicity of the dataset.
From my experience, deep and wide architectures don't exhibit superb performance on simple problems and also require a lot more compute power.
Nevertheless, smaller networks are prone to fail extracting fine features of the input (more on this in the conclusion section).

The Generator and the Discriminator both have the same depth. 
With this it is attempted to keep a fragile balance between two networks.
The Discriminator must have enough capacity not to be severely deluded by the Generator, but not superior to the Generator allowing it to eventually evolve.
The dimension of the latent variable vector is chosen to be 100 as commonly used value for this kind of problems.
Discriminator is realised with Leaky ReLU activations to avoid sparse gradients.

See Tensorboard for model architecture visualisation.

### 1.3 Optimizer and hyperparameters

Adaptive momentum (Adam) optimizer is used in this work.
While my personal preference is to use stochastic optimization methods in general, GANs are usually trained with Adam.

GANs are known to be quite unstable and sensitive to hyperparameters.
The learn rate equals to 3e-4 as such value is frequently reported performing well.
Other values were tested as well, namely 1e-5, 1e-4, and 2e-4, but none of those made the results better.
Primary momentum of the Adam is decreased to 0.7.
This trick is inspired by the [original DCGAN paper](https://arxiv.org/abs/1511.06434).
They used a 0.5 for the primary momentum to slow down networks' evolution. 
It is believed that such value of the parameter helps agents to react to the change of strategy of the corresponding adversary.
In this work however, a bit higher value is used to introduce a bit more instability to the learning process.
I believe, a bit higher value speeds up the training process and destabilizes the system when none of the players improve their results.
Arguably, this can also lead to the issues when the system starts to converge (more on this in the conclusion section).
See the full list of hyperparameters in the table below.

| Hyperparameter              	| Value 	|
|-----------------------------	|-------	|
| Learn rate                  	| 3e-4  	|
| Generator learn rate factor 	| 1     	|
| Weight decay                	| 0     	|
| Primary momentum            	| 0.7   	|
| Secondary momentum          	| 0.999 	|

Weight decay (an L2 norm for the network weights) is kept 0. 
No concrete reasoning here. 
I am just not sure how weight regularization is going to affect the training, therefore it is not included for now.
All networks' weights are initialized with random numbers drawn from normal distribution with standard deviation of 0.2 and mean of 0 for convolutional layers and mean of 0 for batch normalization layers.

### 1.4 Loss function and training

Binary Cross Entropy loss is utilized to calculate the Generator and the Discriminator losses. 
Variation with logits is preferred for its better numerical stability.
While the Discriminator's loss formulation is taken from [original DCGAN paper](https://arxiv.org/abs/1511.06434),
the Generator's original loss formulation is prone to vanishing gradients due to saturation at the lower bound.
The following formulation is used in this project, which is just a negative Discriminator loss.
The reasoning for this is quite intuitive, as the Generator in this setup tries to maximise the Discriminator loss.
In practice this is simply done by calculating the Discriminator loss on fake images with flipped labels (real labels).

**A few tricks**

To save some time, I studied the best practices for GAN trainings ([source](https://github.com/soumith/ganhacks)) and applied a couple in this work.
Firstly, labels for the real and fake images are smoothed to be 0.9 and 0.1, respectively.
This trick allows the Generator to become more robust and avoid extreme predictions.
Secondly, latent vector *h* is sampled from normal distribution as it makes minimum assumptions about the data and allows for better training ([source](https://arxiv.org/abs/1609.04468)).
This is motivated by the central limit theorem, which proves that the combination of multiple estimators tend to form a normal distribution (like multiple dice experiment).
Thirdly, as the Generator's last activation is hyperbolic tangent, the real images are rescaled to the domain of Tanh, namely [-1, 1].


# Task 2: Understanding latent variable space

---

It is well known that simple vector arithmetics on latent representation space can result in peculiar outcomes. 
For example, linear interpolation between latent representation of two generated images would provide a smooth transition from the former image to the latter.
However, extracting a latent representation of an image given a fixed generator is not so trivial. 
In this particular case, the latent space is a 100-dimensional hypersphere (due to the normal distribution). 
Additionally, the objective function for the latent variable vector optimization is not obvious.
In this section I am discussing two major approaches to finding a latent representation of an image given a fixed Generator.

## 2.1 Encoder

This part focuses on deriving a latent representation of an image using a NN.
Obvious benefit of this approach is performance. 
Once trained, new input images will be mapped to the latent space with a single forward pass.
However, NNs, in essence, are polynomial approximators, therefore are very sensitive to the input domain. 
Like Taylor approximation, NN becomes unreliable as the inputs start to significantly deviate from previously seen dataset.

### 2.1.1 Solution approach

Two approaches are developed to tackle this task.

**Encoder V1**

This version of the Encoder network takes an image from the dataset as an input and outputs a corresponding latent representation.
The loss function here is a simple Mean Squared Error Loss with summation reduction. 
The architecture of the Encoder is somewhat similar to the Discriminator from the Task 1.
Additionally, it has a several residual blocks ([ResNet paper](https://arxiv.org/abs/1512.03385)) at the end followed by a fully-connected linear layer and no activation in the end.

**Encoder V2**

The second realisation of the Encoder is inspired by the [Pix2Pix model](https://arxiv.org/abs/1611.07004).
The Encoder and the fixed Generator are combined in a single unit aimed to take an image as an input and produce the realistic and similar image as an output.
The loss function for the Encoder-Generator unit is based on the Discriminator part, which goal is to classify the inputs into real and fake groups.
The Discriminator takes pairs of real and real & fake images with corresponding labels and learns to classify these pairs.
The function of the Discriminator in this architecture is to provide a good objective function for the Encoder. 
This way the design of a good objective function is delegated to the Discriminator in contrast to the **Encoder V1**.
There are no special tricks here, I just implemented the original approach with minor changes in order to keep my model relatively simple and cheap.
Important to note, only the Encoder and Discriminator weights are tuned using separate instances of Adam optimizer.

### 2.1.2 Optimizer and hyperparameters

Again, Adam optimizer is used as widely praised technique, although I am not a big fan of it.
The list hyperparameters is given in the table below.

| Hyperparameter              	| Value 	|
|-----------------------------	|-------	|
| Learn rate                  	| 3e-4  	|
| Generator learn rate factor 	| 1     	|
| Weight decay                	| 0     	|
| Primary momentum            	| 0.5   	|
| Secondary momentum          	| 0.999 	|
| Number or residual layers     | 3         |

A couple of test runs with the primary momentum of 0.7 as in Task 1 didn't result in plausible outcomes and exhibited strange loss dynamics.
Therefore, I decided to further reduce this value to 0.5.

### 2.1.3 Loss function and training

**Encoder V1**

While analysing the loss graph of this model, I noticed unexpected values of MSE loss. 
The values are below 0, which is impossible given the formulation of this function. 
I am convinced, this is just a bug in the code that prepares the input calls the function.
Otherwise, model is still able to learn something reasonable and gradually improve the output pictures quality.
Since this solution was not trained till convergence, it would not be reasonable to make strong conclusions about its performance.
Nevertheless, it is anticipated that longer training and appropriate loss function implementation would allow this solution to output the desired input latent representation.

**Encoder V2**

In the original [Pix2Pix model](https://arxiv.org/abs/1611.07004) the authors use aim to transition from one picture to another and use two sets of real images.
Here, however, I use the only one set of real images. This makes it very easy for the Discriminator to identify real and fake pairs as real pairs are absolutely identical.
This potentially could strongly affect the Generator's capacity to evolve, especially given that the Decoder part of the Generator is fixed.


## 2.2 Iterative approach

This part aims to find a latent representation of an image using iterative optimization method.
Iterative approach is not as efficient as Encoder in this task, however it is a lot less sensitive to the search space.
Moreover, iterative optimizer can also serve as a quick check of the GAN's quality. 
If the optimizer is able to properly match input image to the target output, it indicates that GAN had successfully captured latent representation mapping.
In this section I focus on stochastic methods (meta-heuristics). 
Given a high complexity of the search space (non-linear, multimodal) selecting heuristic approach was natural.
Given abundance of methods of Monte-Carlo techniques, algorithms selection was motivated fulfill the problem requirements and trivial intuition.
Furthermore, more flexible schemes were utilized to allow for problem specific adjustments.

### 2.2.1 Simulated annealing

**Motivation**

Simulated annealing is inspired by the physical system. It imitates the process of cooling where the allowed states decrease with the temperature (cooling schedule).
This approach can effectively navigate through complex functions and escape local minima using probabilistic state acceptance criteria.
The objective function is constructed as MSE loss with summation reduction between the real image, and the image produced by the pre-trained Generator.

**Hyperparameters tuning**

Given the high computational cost of this method partially induced by the objective function calculation and time constraint, hyperparameters were not extensively tuned.
Yet some trial and error runs were performed to arrive to the present formulation of the objective function and better cooling schedule.
The maximum number of iterations is set to 1000.

### 2.2.2 Global particle swarm optimization

**Motivation**

Particle swarm optimization is a nature inspired algorithms that nicely balances local and global space exploration.
Even more, this algorithm allows the particle to share the information about gathered insights and prioritize a certain destinations.
This method also implements a local minima escape mechanism which drastically improves the quality of optimization.
Ideally, hyperparameter search can be applied to enhance the quality of the results.
Yet in this project the number of particles is excessive, since the primary goal is to prove the concept in the first place. 

**Hyperparameters tuning**

The most successful run has the following hyperparameters:

| Hyperparameter              	| Value 	|
|-----------------------------	|-------	|
| Cognitive factor             	| 0.5     	|
| Social factor              	| 0.3    	|
| Inertia                   	| 0.9     	|
| Number of particles          	| 3000   	|
| Maximum number of iterations  | 1000      |

Particular values are chosen to satisfy the convergence criteria and prioritise the search space exploration.


# Conclusion and future work

---

### DCGAN performance

Overall, the performance of DCGAN is satisfactory. 
Pictures mostly look realistic for such a simple model.
Corresponding plots exhibit the expected behavior. 
At the early epochs the networks compete affecting each other's loss, but none of them is clearly dominating.
Towards the end of training the agents reach a plateau and do not improve or fail dramatically.
Instabilities do not disappear even at the late training, which is also might be the consequence of the higher primary momentum of the Adam optimizer.

### Encoder performance

Unfortunately, none of the Encoder variations are fully trained due to the time constraint. 
Nevertheless, **Encoder V1** exhibits gradual improvements in the image quality.
However, there quite a few problems with this approach. 
First, the negative MSE loss is clearly not alright. 
At this point, I don't a definite explanation, and it needs further investigation. 
Most likely, this is just a bug in the train loop and loss function invocation.

The experimentation with **Encoder V2** are limited by the computational power of my machine.
Therefore, I avoid drawing concrete statements. 
Yet I genuinely believe that the approach has a great potential and would definitely work in this direction.

### Iterative optimization

Monte-Carlo search techniques showed surprisingly good performance, especially the simulated annealing approach. 
The results of the optimization algorithm indicates that the space provides enough information to navigate in.
Additionally, good performance of this class of methods indirectly indicates good GAN mapping ability.

### Future work

In this paragraph I list a number of potential improvements to the existing solutions along with the thoughts for the future work.

**DCGAN**

- Experiment with deeper and wider models
- Use Weights & Biases service to perform a hyperparameter sweep
- Experiment with weights regularization (for instance, weight decay)

**Encoder**

- Investigate the negative loss values for the **Encoder V1**
- Experiment with the loss formulation for the pair of real images for the Discriminator's loss in **Encoder V2** architecture
- Let it train for longer time (both versions)
- Experiment with the activation for the last layer of the Encoders; make it map the input image to the range of values of [-3, 3] (which is the 99.7% of the normal distribution)
- Try the architectures without fully-connected linear layers
- Use pre-trained Discriminator from the Task 1

**Particle swarm optimization**

- Perform stochastic hyperparameter search to find the best combination for this problem

**Future developments and funny ideas**

- Experiment more with conditional GANs (like Pix2Pix) to extract more information from the input images and have more control over the desired output
- Try to use gradient based methods for extracting a picture's latent representation (like cross-entropy method)
- Add Pareto optimality criterion to the loss of the **Encoder V1** (the standard deviation of the individual loss components distribution)


# Reflection

---

> **Note**: this section is intended to share my feedback on this task and reflect on the obtained experiences. 
It is meant to be rather casual, and a bit emotional :-)

Well, it is genuinely exciting to finally put my hands on GANs. 
I learned a lot about theoretical motivation for this branch of Deep Learning, as well as about practical aspects of training such models.
It feels like GANs have a lot in common with RL, particularly with Multi-Agent RL. 
The capabilities of this family of algorithms is inspiring, though it definitely requires a lot of research.
What amazed me the most is that simulated annealing was able to optimize the latent input representation almost perfectly. 
This literally blew my mind because I was convinced solving the problem this way would be impossible. 
100-dimensional search space sounds like way too much for such optimizer.

It is a bit regretful though that I didn't have a good pipeline for GANs prior to this moment. 
A lot of things could've been done differently.
Well, it is a well known truth: only when the project is finished you realise how it should've been done.

Overall, this project happened to be a great opportunity to learn new things and try peculiar solutions to non-trivial problems.
I genuinely enjoyed working on this one and would definitely make something else on GANs in the future.
It was also a pleasure to read this task as it is well and clearly formulated.
